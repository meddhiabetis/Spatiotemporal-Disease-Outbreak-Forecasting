{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "                                                  ID  Total  \\\n",
      "0  ID_3a11929e-3317-476d-99f7-1bd9fb58f018_12_202...    0.0   \n",
      "1  ID_3a11929e-3317-476d-99f7-1bd9fb58f018_12_202...    0.0   \n",
      "2  ID_3a11929e-3317-476d-99f7-1bd9fb58f018_12_202...    0.0   \n",
      "3  ID_3a11929e-3317-476d-99f7-1bd9fb58f018_12_202...    0.0   \n",
      "4  ID_3a11929e-3317-476d-99f7-1bd9fb58f018_12_202...    0.0   \n",
      "\n",
      "                                  Location  \\\n",
      "0  ID_3a11929e-3317-476d-99f7-1bd9fb58f018   \n",
      "1  ID_3a11929e-3317-476d-99f7-1bd9fb58f018   \n",
      "2  ID_3a11929e-3317-476d-99f7-1bd9fb58f018   \n",
      "3  ID_3a11929e-3317-476d-99f7-1bd9fb58f018   \n",
      "4  ID_3a11929e-3317-476d-99f7-1bd9fb58f018   \n",
      "\n",
      "          Category_Health_Facility_UUID    Disease  Month  Year  \\\n",
      "0  a9280aca-c872-46f5-ada7-4a7cc31cf6ec  Dysentery     12  2022   \n",
      "1  a9280aca-c872-46f5-ada7-4a7cc31cf6ec    Typhoid     12  2022   \n",
      "2  a9280aca-c872-46f5-ada7-4a7cc31cf6ec   Diarrhea     12  2022   \n",
      "3  a9280aca-c872-46f5-ada7-4a7cc31cf6ec   Diarrhea     12  2022   \n",
      "4  a9280aca-c872-46f5-ada7-4a7cc31cf6ec   Diarrhea     12  2022   \n",
      "\n",
      "   Transformed_Latitude  Transformed_Longitude  \n",
      "0              -8.62982               68.23267  \n",
      "1              -8.62982               68.23267  \n",
      "2              -8.62982               68.23267  \n",
      "3              -8.62982               68.23267  \n",
      "4              -8.62982               68.23267  \n",
      "\n",
      "Waste Management Dataset:\n",
      "   Year  Month       10u       10v       2d       2t     evabs     evaow  \\\n",
      "0  2019      1 -1.006850 -0.714544  293.502  297.417 -0.002489 -0.001031   \n",
      "1  2019      2 -1.408560 -0.662555  292.943  297.978 -0.002556 -0.001076   \n",
      "2  2019      3 -0.892110 -0.449448  293.250  297.989 -0.002535 -0.000980   \n",
      "3  2019      4 -0.392348  0.384925  293.934  296.542 -0.001748 -0.000658   \n",
      "4  2019      5 -0.447104  0.581028  292.571  294.726 -0.001374 -0.000462   \n",
      "\n",
      "      evatc         evavt  ...        tp     swvl1     swvl2     swvl3  \\\n",
      "0 -0.000989 -3.445890e-08  ...  0.006655  0.346542  0.335724  0.264359   \n",
      "1 -0.000734 -3.818420e-08  ...  0.003201  0.254517  0.259918  0.281769   \n",
      "2 -0.000713 -3.678720e-08  ...  0.004682  0.278152  0.284195  0.261597   \n",
      "3 -0.001343 -2.700840e-08  ...  0.007518  0.385513  0.378616  0.309784   \n",
      "4 -0.001139 -2.048910e-08  ...  0.005989  0.397659  0.400055  0.392654   \n",
      "\n",
      "      swvl4  Transformed_Latitude  Transformed_Longitude  Month_Year  \\\n",
      "0  0.300018              -8.58518               68.25058      1_2019   \n",
      "1  0.296188              -8.58518               68.25058      2_2019   \n",
      "2  0.291672              -8.58518               68.25058      3_2019   \n",
      "3  0.288925              -8.58518               68.25058      4_2019   \n",
      "4  0.309311              -8.58518               68.25058      5_2019   \n",
      "\n",
      "             lat_lon        Month_Year_lat_lon  \n",
      "0  -8.58518_68.25058  1_2019_-8.58518_68.25058  \n",
      "1  -8.58518_68.25058  2_2019_-8.58518_68.25058  \n",
      "2  -8.58518_68.25058  3_2019_-8.58518_68.25058  \n",
      "3  -8.58518_68.25058  4_2019_-8.58518_68.25058  \n",
      "4  -8.58518_68.25058  5_2019_-8.58518_68.25058  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "\n",
      "Toilets Dataset:\n",
      "   Year  Month       10u       10v       2d       2t     evabs     evaow  \\\n",
      "0  2019      1 -1.006850 -0.714544  293.502  297.417 -0.002489 -0.001031   \n",
      "1  2019      2 -1.408560 -0.662555  292.943  297.978 -0.002556 -0.001076   \n",
      "2  2019      3 -0.892110 -0.449448  293.250  297.989 -0.002535 -0.000980   \n",
      "3  2019      4 -0.392348  0.384925  293.934  296.542 -0.001748 -0.000658   \n",
      "4  2019      5 -0.447104  0.581028  292.571  294.726 -0.001374 -0.000462   \n",
      "\n",
      "      evatc         evavt  ...        tp     swvl1     swvl2     swvl3  \\\n",
      "0 -0.000989 -3.445890e-08  ...  0.006655  0.346542  0.335724  0.264359   \n",
      "1 -0.000734 -3.818420e-08  ...  0.003201  0.254517  0.259918  0.281769   \n",
      "2 -0.000713 -3.678720e-08  ...  0.004682  0.278152  0.284195  0.261597   \n",
      "3 -0.001343 -2.700840e-08  ...  0.007518  0.385513  0.378616  0.309784   \n",
      "4 -0.001139 -2.048910e-08  ...  0.005989  0.397659  0.400055  0.392654   \n",
      "\n",
      "      swvl4  Transformed_Latitude  Transformed_Longitude  Month_Year  \\\n",
      "0  0.300018              -8.61768               68.24536      1_2019   \n",
      "1  0.296188              -8.61768               68.24536      2_2019   \n",
      "2  0.291672              -8.61768               68.24536      3_2019   \n",
      "3  0.288925              -8.61768               68.24536      4_2019   \n",
      "4  0.309311              -8.61768               68.24536      5_2019   \n",
      "\n",
      "             lat_lon        Month_Year_lat_lon  \n",
      "0  -8.61768_68.24536  1_2019_-8.61768_68.24536  \n",
      "1  -8.61768_68.24536  2_2019_-8.61768_68.24536  \n",
      "2  -8.61768_68.24536  3_2019_-8.61768_68.24536  \n",
      "3  -8.61768_68.24536  4_2019_-8.61768_68.24536  \n",
      "4  -8.61768_68.24536  5_2019_-8.61768_68.24536  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "\n",
      "Water Sources Dataset:\n",
      "   Year  Month       10u       10v       2d       2t     evabs     evaow  \\\n",
      "0  2019      1 -1.006850 -0.714544  293.502  297.417 -0.002489 -0.001031   \n",
      "1  2019      2 -1.408560 -0.662555  292.943  297.978 -0.002556 -0.001076   \n",
      "2  2019      3 -0.892110 -0.449448  293.250  297.989 -0.002535 -0.000980   \n",
      "3  2019      4 -0.392348  0.384925  293.934  296.542 -0.001748 -0.000658   \n",
      "4  2019      5 -0.447104  0.581028  292.571  294.726 -0.001374 -0.000462   \n",
      "\n",
      "      evatc         evavt  ...        tp     swvl1     swvl2     swvl3  \\\n",
      "0 -0.000989 -3.445890e-08  ...  0.006655  0.346542  0.335724  0.264359   \n",
      "1 -0.000734 -3.818420e-08  ...  0.003201  0.254517  0.259918  0.281769   \n",
      "2 -0.000713 -3.678720e-08  ...  0.004682  0.278152  0.284195  0.261597   \n",
      "3 -0.001343 -2.700840e-08  ...  0.007518  0.385513  0.378616  0.309784   \n",
      "4 -0.001139 -2.048910e-08  ...  0.005989  0.397659  0.400055  0.392654   \n",
      "\n",
      "      swvl4  Transformed_Latitude  Transformed_Longitude  Month_Year  \\\n",
      "0  0.300018              -8.57424               68.23761      1_2019   \n",
      "1  0.296188              -8.57424               68.23761      2_2019   \n",
      "2  0.291672              -8.57424               68.23761      3_2019   \n",
      "3  0.288925              -8.57424               68.23761      4_2019   \n",
      "4  0.309311              -8.57424               68.23761      5_2019   \n",
      "\n",
      "             lat_lon        Month_Year_lat_lon  \n",
      "0  -8.57424_68.23761  1_2019_-8.57424_68.23761  \n",
      "1  -8.57424_68.23761  2_2019_-8.57424_68.23761  \n",
      "2  -8.57424_68.23761  3_2019_-8.57424_68.23761  \n",
      "3  -8.57424_68.23761  4_2019_-8.57424_68.23761  \n",
      "4  -8.57424_68.23761  5_2019_-8.57424_68.23761  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "Missing Values in Train Dataset:\n",
      "ID                               0\n",
      "Total                            1\n",
      "Location                         0\n",
      "Category_Health_Facility_UUID    0\n",
      "Disease                          0\n",
      "Month                            0\n",
      "Year                             0\n",
      "Transformed_Latitude             0\n",
      "Transformed_Longitude            0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Waste Management Dataset:\n",
      "Year                     0\n",
      "Month                    0\n",
      "10u                      0\n",
      "10v                      0\n",
      "2d                       0\n",
      "2t                       0\n",
      "evabs                    0\n",
      "evaow                    0\n",
      "evatc                    0\n",
      "evavt                    0\n",
      "albedo                   0\n",
      "lshf                     0\n",
      "lai_hv                   0\n",
      "lai_lv                   0\n",
      "pev                      0\n",
      "ro                       0\n",
      "src                      0\n",
      "skt                      0\n",
      "es                       0\n",
      "stl1                     0\n",
      "stl2                     0\n",
      "stl3                     0\n",
      "stl4                     0\n",
      "ssro                     0\n",
      "slhf                     0\n",
      "ssr                      0\n",
      "str                      0\n",
      "sp                       0\n",
      "sro                      0\n",
      "sshf                     0\n",
      "ssrd                     0\n",
      "strd                     0\n",
      "e                        0\n",
      "tp                       0\n",
      "swvl1                    0\n",
      "swvl2                    0\n",
      "swvl3                    0\n",
      "swvl4                    0\n",
      "Transformed_Latitude     0\n",
      "Transformed_Longitude    0\n",
      "Month_Year               0\n",
      "lat_lon                  0\n",
      "Month_Year_lat_lon       0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Toilets Dataset:\n",
      "Year                     0\n",
      "Month                    0\n",
      "10u                      0\n",
      "10v                      0\n",
      "2d                       0\n",
      "2t                       0\n",
      "evabs                    0\n",
      "evaow                    0\n",
      "evatc                    0\n",
      "evavt                    0\n",
      "albedo                   0\n",
      "lshf                     0\n",
      "lai_hv                   0\n",
      "lai_lv                   0\n",
      "pev                      0\n",
      "ro                       0\n",
      "src                      0\n",
      "skt                      0\n",
      "es                       0\n",
      "stl1                     0\n",
      "stl2                     0\n",
      "stl3                     0\n",
      "stl4                     0\n",
      "ssro                     0\n",
      "slhf                     0\n",
      "ssr                      0\n",
      "str                      0\n",
      "sp                       0\n",
      "sro                      0\n",
      "sshf                     0\n",
      "ssrd                     0\n",
      "strd                     0\n",
      "e                        0\n",
      "tp                       0\n",
      "swvl1                    0\n",
      "swvl2                    0\n",
      "swvl3                    0\n",
      "swvl4                    0\n",
      "Transformed_Latitude     0\n",
      "Transformed_Longitude    0\n",
      "Month_Year               0\n",
      "lat_lon                  0\n",
      "Month_Year_lat_lon       0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Water Sources Dataset:\n",
      "Year                      0\n",
      "Month                     0\n",
      "10u                       0\n",
      "10v                       0\n",
      "2d                        0\n",
      "2t                        0\n",
      "evabs                     0\n",
      "evaow                     0\n",
      "evatc                     0\n",
      "evavt                     0\n",
      "albedo                    0\n",
      "lshf                      0\n",
      "lai_hv                    0\n",
      "lai_lv                    0\n",
      "pev                       0\n",
      "ro                        0\n",
      "src                       0\n",
      "skt                       0\n",
      "es                        0\n",
      "stl1                      0\n",
      "stl2                      0\n",
      "stl3                      0\n",
      "stl4                      0\n",
      "ssro                      0\n",
      "slhf                      0\n",
      "ssr                       0\n",
      "str                       0\n",
      "sp                        0\n",
      "sro                       0\n",
      "sshf                      0\n",
      "ssrd                      0\n",
      "strd                      0\n",
      "e                         0\n",
      "tp                        0\n",
      "swvl1                     0\n",
      "swvl2                     0\n",
      "swvl3                     0\n",
      "swvl4                     0\n",
      "Transformed_Latitude     60\n",
      "Transformed_Longitude    60\n",
      "Month_Year                0\n",
      "lat_lon                   0\n",
      "Month_Year_lat_lon        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X and y have inconsistent numbers of samples: 48 vs 57",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 158\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# Ensure X and y have the same number of samples\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX and y have inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Split data into train and test sets\u001b[39;00m\n\u001b[0;32m    162\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: X and y have inconsistent numbers of samples: 48 vs 57"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Spatio-Temporal Analysis with STARMA\n",
    "# \n",
    "# This notebook preprocesses the data and applies a STARMA model to analyze spatiotemporal patterns in disease outbreaks.\n",
    "\n",
    "# %%\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial import cKDTree\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# %%\n",
    "# Load datasets\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(\"../data/raw/Train.csv\")\n",
    "    waste_df = pd.read_csv(\"../data/raw/waste_management.csv\")\n",
    "    toilets_df = pd.read_csv(\"../data/raw/toilets.csv\")\n",
    "    water_df = pd.read_csv(\"../data/raw/water_sources.csv\")\n",
    "    return train_df, waste_df, toilets_df, water_df\n",
    "\n",
    "train_df, waste_df, toilets_df, water_df = load_data()\n",
    "\n",
    "# %%\n",
    "# Inspect datasets\n",
    "print(\"Train Dataset:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nWaste Management Dataset:\")\n",
    "print(waste_df.head())\n",
    "print(\"\\nToilets Dataset:\")\n",
    "print(toilets_df.head())\n",
    "print(\"\\nWater Sources Dataset:\")\n",
    "print(water_df.head())\n",
    "\n",
    "# %%\n",
    "# Check for missing values\n",
    "print(\"Missing Values in Train Dataset:\")\n",
    "print(train_df.isnull().sum())\n",
    "print(\"\\nMissing Values in Waste Management Dataset:\")\n",
    "print(waste_df.isnull().sum())\n",
    "print(\"\\nMissing Values in Toilets Dataset:\")\n",
    "print(toilets_df.isnull().sum())\n",
    "print(\"\\nMissing Values in Water Sources Dataset:\")\n",
    "print(water_df.isnull().sum())\n",
    "\n",
    "# %%\n",
    "# Rename columns for clarity\n",
    "def rename_columns(df, prefix):\n",
    "    for col in df.columns:\n",
    "        if col not in ['Month_Year_lat_lon', 'lat_lon']:\n",
    "            df.rename(columns={col: f\"{prefix}_{col}\"}, inplace=True)\n",
    "\n",
    "rename_columns(toilets_df, \"toilet\")\n",
    "rename_columns(waste_df, \"waste\")\n",
    "rename_columns(water_df, \"water\")\n",
    "\n",
    "# %%\n",
    "# Drop rows with missing latitude and longitude in supplementary datasets\n",
    "for df, prefix in [(toilets_df, 'toilet'), (waste_df, 'waste'), (water_df, 'water')]:\n",
    "    df.dropna(subset=[f\"{prefix}_Transformed_Latitude\", f\"{prefix}_Transformed_Longitude\"], inplace=True)\n",
    "\n",
    "# %%\n",
    "# Function to find nearest locations\n",
    "def find_nearest(hospital_df, location_df, lat_col, lon_col, id_col):\n",
    "    \"\"\"\n",
    "    Find the nearest location in `location_df` for each hospital in `hospital_df`.\n",
    "    \n",
    "    Parameters:\n",
    "        hospital_df (pd.DataFrame): Hospital data with latitude and longitude.\n",
    "        location_df (pd.DataFrame): Location data (e.g., waste, toilets, water sources).\n",
    "        lat_col (str): Latitude column in `location_df`.\n",
    "        lon_col (str): Longitude column in `location_df`.\n",
    "        id_col (str): Unique identifier column in `location_df`.\n",
    "    \n",
    "    Returns:\n",
    "        nearest (dict): A dictionary mapping hospital IDs to the nearest location ID.\n",
    "    \"\"\"\n",
    "    # Create a cKDTree for efficient nearest neighbour search\n",
    "    tree = cKDTree(location_df[[lat_col, lon_col]].values)\n",
    "    nearest = {}\n",
    "    # Loop through each hospital and find the nearest site in location_df\n",
    "    for _, row in hospital_df.iterrows():\n",
    "        _, idx = tree.query([row['Transformed_Latitude'], row['Transformed_Longitude']])\n",
    "        nearest[row['ID']] = location_df.iloc[idx][id_col]\n",
    "    return nearest\n",
    "\n",
    "# %%\n",
    "# Ensure unique identifier columns exist in all supplementary datasets\n",
    "for df, prefix in [(toilets_df, 'toilet'), (waste_df, 'waste'), (water_df, 'water')]:\n",
    "    df[f\"{prefix}_Month_Year_lat_lon\"] = (\n",
    "        df[f\"{prefix}_Month_Year\"] + '_' +\n",
    "        df[f\"{prefix}_Transformed_Latitude\"].astype(str) + '_' +\n",
    "        df[f\"{prefix}_Transformed_Longitude\"].astype(str)\n",
    "    )\n",
    "\n",
    "# %%\n",
    "# Merge datasets with nearest locations\n",
    "merged_data = train_df.copy()\n",
    "datasets = [\n",
    "    (toilets_df, 'toilet', 'toilet_Month_Year_lat_lon'),\n",
    "    (waste_df, 'waste', 'waste_Month_Year_lat_lon'),\n",
    "    (water_df, 'water', 'water_Month_Year_lat_lon'),\n",
    "]\n",
    "\n",
    "for df, prefix, id_col in datasets:\n",
    "    nearest = find_nearest(merged_data, df, f\"{prefix}_Transformed_Latitude\", f\"{prefix}_Transformed_Longitude\", id_col)\n",
    "    nearest_df = pd.DataFrame(list(nearest.items()), columns=['ID', id_col])\n",
    "    merged_data = merged_data.merge(nearest_df, on=\"ID\").merge(df, on=id_col)\n",
    "\n",
    "# %%\n",
    "# Select relevant columns for modeling\n",
    "model_data = merged_data[['ID', 'Year', 'Month', 'Total', 'Transformed_Latitude', 'Transformed_Longitude'] + \n",
    "              ['waste_2t', 'waste_tp', 'waste_swvl1', 'waste_swvl2', 'waste_swvl3', 'waste_swvl4', 'waste_10u', 'waste_10v']]  # Example climate variables\n",
    "\n",
    "# %%\n",
    "# Aggregate data by location and time\n",
    "agg_data = model_data.groupby(['Transformed_Latitude', 'Transformed_Longitude', 'Year', 'Month']).agg({\n",
    "    'Total': 'sum',  # Sum of outbreaks\n",
    "    'waste_2t': 'mean',    # Average temperature\n",
    "    'waste_tp': 'mean',    # Average precipitation\n",
    "    'waste_swvl1': 'mean', # Average soil water content\n",
    "}).reset_index()\n",
    "\n",
    "# %%\n",
    "# Create a time series for each location\n",
    "time_series_data = agg_data.pivot_table(\n",
    "    index=['Transformed_Latitude', 'Transformed_Longitude'],\n",
    "    columns=['Year', 'Month'],\n",
    "    values='Total'\n",
    ").fillna(0)\n",
    "\n",
    "# %%\n",
    "# Prepare data for STARMA model\n",
    "def prepare_starma_data(time_series_data):\n",
    "    \"\"\"\n",
    "    Prepare data for STARMA modeling.\n",
    "    \n",
    "    Parameters:\n",
    "        time_series_data (pd.DataFrame): Pivoted time series data.\n",
    "    \n",
    "    Returns:\n",
    "        X (np.array): Feature matrix (time series for each location).\n",
    "        y (np.array): Target variable (outbreaks).\n",
    "    \"\"\"\n",
    "    X = time_series_data.values.T  # Transpose to get time series for each location\n",
    "    y = time_series_data.sum(axis=1).values  # Total outbreaks per location\n",
    "    return X, y\n",
    "\n",
    "X, y = prepare_starma_data(time_series_data)\n",
    "\n",
    "# %%\n",
    "# Ensure X and y have the same number of samples\n",
    "if X.shape[0] != y.shape[0]:\n",
    "    raise ValueError(f\"X and y have inconsistent numbers of samples: {X.shape[0]} vs {y.shape[0]}\")\n",
    "\n",
    "# %%\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# %%\n",
    "# Fit STARMA model\n",
    "def fit_starma_model(X_train, y_train, order=(1, 0, 1)):\n",
    "    \"\"\"\n",
    "    Fit a STARMA model to the data.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (np.array): Training feature matrix.\n",
    "        y_train (np.array): Training target variable.\n",
    "        order (tuple): (p, d, q) order of the STARMA model.\n",
    "    \n",
    "    Returns:\n",
    "        model: Fitted STARMA model.\n",
    "    \"\"\"\n",
    "    model = SARIMAX(y_train, exog=X_train, order=order)\n",
    "    fitted_model = model.fit(disp=False)\n",
    "    return fitted_model\n",
    "\n",
    "starma_model = fit_starma_model(X_train, y_train, order=(1, 0, 1))\n",
    "\n",
    "# %%\n",
    "# Make predictions\n",
    "def predict_starma(model, X_test):\n",
    "    \"\"\"\n",
    "    Make predictions using the STARMA model.\n",
    "    \n",
    "    Parameters:\n",
    "        model: Fitted STARMA model.\n",
    "        X_test (np.array): Test feature matrix.\n",
    "    \n",
    "    Returns:\n",
    "        predictions (np.array): Predicted values.\n",
    "    \"\"\"\n",
    "    predictions = model.forecast(steps=len(X_test), exog=X_test)\n",
    "    return predictions\n",
    "\n",
    "predictions = predict_starma(starma_model, X_test)\n",
    "\n",
    "# %%\n",
    "# Evaluate model\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# %%\n",
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(predictions, label='Predicted')\n",
    "plt.title('STARMA Model: Actual vs Predicted Outbreaks')\n",
    "plt.xlabel('Location Index')\n",
    "plt.ylabel('Number of Outbreaks')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
